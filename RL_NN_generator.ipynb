{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMQo5l2Wsu0u",
        "outputId": "5091d758-91dd-43f8-cb3d-bb4cf616e4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please type yout stage names\n",
            "(start with alphabet, lowercase and number, split by underscore(_), e.g. my_env_v1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def make_dirs(env_name: str):\n",
        "    os.makedirs('gym_{}'.format(env_name))\n",
        "    os.makedirs('gym_{}/envs'.format(env_name))\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_files(env_name: str, stage_names):\n",
        "    registry_init = 'gym_{}/__init__.py'.format(env_name)\n",
        "    with open(registry_init, 'w') as f:\n",
        "        f.write('from gym.envs.registration import register\\n\\n')\n",
        "        for name in stage_names:\n",
        "            register_str = \"register(\\n    id='{}',\\n    entry_point='gym_{}.envs:{}',\\n)\\n\".format(name,\n",
        "                                                                                                    env_name,\n",
        "                                                                                                    ''.join([s.capitalize()for s in name.split('_')]))\n",
        "            f.write(register_str)\n",
        "    envs_init = 'gym_{}/envs/__init__.py'.format(env_name)\n",
        "    with open(envs_init, 'w') as f:\n",
        "        for name in stage_names:\n",
        "            import_str = \"from gym_{}.envs.{} import {}\\n\".format(env_name, name,\n",
        "                                                                  ''.join([s.capitalize() for s in name.split('_')]))\n",
        "            f.write(import_str)\n",
        "\n",
        "    head = \"\"\"import gymnasium as gym\n",
        "from gymnasium import spaces, utils\n",
        "#from gymnasium.utils import seeding\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    tail = \"\"\"\n",
        "\n",
        "  metadata = {'render_modes': ['human']}\n",
        "  # actions agent can do\n",
        "  # you can add here your layers\n",
        "  actions_set = [\n",
        "                # increase channels with kernel 3\n",
        "                #'conv=channel_factor:2,kernel_size:3,stride:1,padding:0-',\n",
        "                'conv=channel_factor:4,kernel_size:3,stride:1,padding:0-',\n",
        "                'conv=channel_factor:8,kernel_size:3,stride:1,padding:0-',\n",
        "                'conv=channel_factor:16,kernel_size:3,stride:1,padding:0-',\n",
        "                # increase channels with kernel 5\n",
        "                #'conv=channel_factor:2,kernel_size:5,stride:1,padding:0-',\n",
        "                'conv=channel_factor:4,kernel_size:5,stride:1,padding:0-',\n",
        "                'conv=channel_factor:8,kernel_size:5,stride:1,padding:0-',\n",
        "                'conv=channel_factor:16,kernel_size:5,stride:1,padding:0-',\n",
        "                # increase channels with kernel 7\n",
        "                #'conv=channel_factor:2,kernel_size:7,stride:1,padding:0-',\n",
        "                #'conv=channel_factor:4,kernel_size:7,stride:1,padding:0-',\n",
        "                #'conv=channel_factor:8,kernel_size:7,stride:1,padding:0-',\n",
        "                #'conv=channel_factor:16,kernel_size:7,stride:1,padding:0-',\n",
        "\n",
        "\n",
        "\n",
        "                # decrease channels with kernel 3\n",
        "                'conv=channel_factor:0.6,kernel_size:3,stride:1,padding:0-',\n",
        "                'conv=channel_factor:0.8,kernel_size:3,stride:1,padding:0-',\n",
        "\n",
        "                # decrease channels with kernel 5\n",
        "                'conv=channel_factor:0.6,kernel_size:5,stride:1,padding:0-',\n",
        "                'conv=channel_factor:0.8,kernel_size:5,stride:1,padding:0-',\n",
        "\n",
        "                # decrease channels with kernel 7\n",
        "                #'conv=channel_factor:0.6,kernel_size:7,stride:1,padding:0-',\n",
        "                #'conv=channel_factor:0.8,kernel_size:7,stride:1,padding:0-',\n",
        "\n",
        "\n",
        "                 'batchnorm=eps:0.00001-',\n",
        "\n",
        "                 'avgpool=kernel_size:2,stride:2,padding:0-',\n",
        "                 #'avgpool=kernel_size:3,stride:3,padding:0-',\n",
        "\n",
        "                 'maxpool=kernel_size:2,stride:2,padding:0-',\n",
        "                 #'maxpool=kernel_size:3,stride:3,padding:0-',\n",
        "\n",
        "                 'dropout=p:0.1-',\n",
        "                 'dropout=p:0.2-',\n",
        "                 #'dropout=p:0.4-',\n",
        "  ]\n",
        "\n",
        "  # Some reward variables\n",
        "  NN_CREATE_SUCCESS_REWARD = 1\n",
        "  NN_CREATE_NOT_SUCCESS_PENALTY = -1\n",
        "\n",
        "  # TODO add not fixed NN length\n",
        "  DEPTH_REWARD_FACTOR = 0.1\n",
        "  METRICS_OPTIMIZATION_FACTOR = 1\n",
        "  NAN_NUM = 100\n",
        "\n",
        "  def __init__(self, opt_cls=None, crit=None, trn_ldr=None, vld_ldr=None, render_mode=None):\n",
        "      '''\n",
        "      Initialization of environment variables\n",
        "      '''\n",
        "\n",
        "      # here is learning params\n",
        "      self.NN_PARAMS = {\n",
        "          'lr': 0.001,\n",
        "          'num_classes': 10, # TODO adaptive num_classes\n",
        "          'train_epochs': 10,\n",
        "          'last_nets_metrics_memory_len': 10,\n",
        "          'layers_amount': 5,\n",
        "          'amount_of_metrics': 2,\n",
        "      }\n",
        "\n",
        "      # here contains NN learning metrics\n",
        "      # uses for observations\n",
        "      # shape=[MEMORY_LEN, N_METRICS, EPOCHS]\n",
        "      self.NN_PARAMS['metrics'] = np.zeros((\n",
        "          self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "          self.NN_PARAMS['amount_of_metrics'],\n",
        "          self.NN_PARAMS['train_epochs'],\n",
        "      ))\n",
        "\n",
        "      # here contains last architectures\n",
        "      # uses for observations\n",
        "      # shape=[MEMORY, N_LAYERS]\n",
        "      self.NN_PARAMS['last_nets_architectures'] = np.zeros((\n",
        "             self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "             self.NN_PARAMS['layers_amount'],\n",
        "          ))\n",
        "\n",
        "      # Variables for NN\n",
        "      self.Net = self.NN()\n",
        "      self.train_dataloader = trn_ldr\n",
        "      self.valid_dataloader = vld_ldr\n",
        "      self.optimizer_class = opt_cls\n",
        "      self.optimizer = None\n",
        "      self.criterion = crit\n",
        "      self.device = 'cuda'\n",
        "\n",
        "      self.nngenerator = self.nnGenerator()\n",
        "\n",
        "      self.last_obs = None\n",
        "\n",
        "      # Action space describes what agent will give to environment\n",
        "      # shape=[ACTION_SET_SIZE, N_LAYERS]\n",
        "      self.action_space = spaces.MultiDiscrete(\n",
        "        [len(self.actions_set)] * self.NN_PARAMS['layers_amount'],\n",
        "         seed=42)\n",
        "\n",
        "      # Observation space describes what agent\n",
        "      # will take from enviromnent as observation\n",
        "      # shape=dict{\n",
        "      #  METRICS, shape as NN_PARAMS['metrics'],\n",
        "      #  ARCHITECTURES, shape as NN_PARAMS['layers_amount'],\n",
        "      # }\n",
        "      self.observation_space = spaces.Dict(\n",
        "          {\n",
        "          'last_nets_metrics_memory': spaces.Box(\n",
        "              low=0,\n",
        "              high=100,\n",
        "              shape=(self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "                     self.NN_PARAMS['amount_of_metrics'],\n",
        "                     self.NN_PARAMS['train_epochs'],\n",
        "                     )),\n",
        "          'last_nets_architectures': spaces.Box(\n",
        "              low=0,\n",
        "              high=len(self.actions_set),\n",
        "              shape=(self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "                     self.NN_PARAMS['layers_amount'],\n",
        "                     ))\n",
        "          }\n",
        "      )\n",
        "\n",
        "      # some variable for collecting statistics\n",
        "\n",
        "      self.statistics = {\n",
        "        'episode_rewards': [],\n",
        "        'global_rewards': [],\n",
        "        'made_steps': [],\n",
        "      }\n",
        "\n",
        "      self.seed()\n",
        "      assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "      self.render_mode = render_mode\n",
        "\n",
        "\n",
        "  class NN(nn.Module):\n",
        "    '''\n",
        "    NN template\n",
        "    Agent's net will be put to self.layers\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      self.layers = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.layers(x)\n",
        "      return x\n",
        "\n",
        "    def __call__(self, x):\n",
        "      return self.forward(x)\n",
        "\n",
        "  def set_train_dataloader(self, train_dataloader):\n",
        "    self.train_dataloader = train_dataloader\n",
        "\n",
        "  def set_valid_dataloader(self, valid_dataloader):\n",
        "    self.valid_dataloader = valid_dataloader\n",
        "\n",
        "  def set_criterion(self, criterion):\n",
        "    self.criterion = criterion\n",
        "\n",
        "  def set_optimizer(self, optimizer):\n",
        "    self.optimizer_class = optimizer\n",
        "\n",
        "  def train(self):\n",
        "    '''\n",
        "    Simple NN training loop\n",
        "    You can add your metrics here\n",
        "\n",
        "    # TODO add smart metrcis choosing\n",
        "\n",
        "    return: all train/valid metrics\n",
        "    '''\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    for i in tqdm(range(0, self.NN_PARAMS['train_epochs'] + 1)):\n",
        "        losses = []\n",
        "        for X, Y in self.train_dataloader:\n",
        "            X = X.float().to(self.device)\n",
        "            Y = Y.float().to(self.device)\n",
        "            preds = self.Net(X)\n",
        "            preds, _ = torch.max(preds,1)\n",
        "            loss = self.criterion(preds, Y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        #print(\"Train Loss : {:.6f}\".format(torch.tensor(losses).mean()))\n",
        "        if i != 0:\n",
        "            train_losses.append(torch.tensor(losses).mean())\n",
        "\n",
        "        with torch.no_grad():\n",
        "            losses = []\n",
        "            for X, Y in self.valid_dataloader:\n",
        "                X = X.float().to(self.device)\n",
        "                Y = Y.float().to(self.device)\n",
        "                preds = self.Net(X)\n",
        "                preds, _ = torch.max(preds,1)\n",
        "                loss = self.criterion(preds,Y)\n",
        "                losses.append(loss.item())\n",
        "            #print(\"Valid Loss : {:.6f}\".format(torch.tensor(losses).mean()))\n",
        "            if i != 0:\n",
        "                valid_losses.append(torch.tensor(losses).mean())\n",
        "\n",
        "    # update all required NN metrics\n",
        "    #print(len(train_losses), train_losses)\n",
        "    #print(len(valid_losses), valid_losses)\n",
        "\n",
        "    return np.array([train_losses, valid_losses])\n",
        "\n",
        "  class nnGenerator():\n",
        "    '''\n",
        "       nnGenerator makes manipulations with\n",
        "       agent's action (preproc for training)\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "      self.text_layers_dict = dict({})\n",
        "      self.nn_len = -1\n",
        "\n",
        "    def action_to_text(self, action, action_set):\n",
        "      '''\n",
        "      Converts MultiDiscrete action to action_text\n",
        "      return: res - str\n",
        "      '''\n",
        "\n",
        "      res = \"\"\n",
        "      for i in action:\n",
        "        res = res + action_set[int(i)]\n",
        "      return res\n",
        "\n",
        "    def parse_action(self, action, action_set):\n",
        "      '''\n",
        "      parse action_text\n",
        "      parsed data puts to self.text_layers_dict\n",
        "      result dict format: 'layer_name': (id, {params})\n",
        "          {\n",
        "            'conv1': (1, {'channel_factor': '123', 'padding': '0', ...}),\n",
        "            'dropout2': (2, {'p': '0.2'}),\n",
        "            ...\n",
        "          }\n",
        "      return None\n",
        "      '''\n",
        "\n",
        "      action = self.action_to_text(action, action_set)\n",
        "      self.text_layers_dict = dict({})\n",
        "      #print(action)\n",
        "      if action[-1] == '-':\n",
        "        action = action[:-1]\n",
        "      text_layers = action.split('-')\n",
        "      id = 0\n",
        "      for text_layer in text_layers:\n",
        "        tmp = text_layer.split('=')\n",
        "        layer_name, layer_params = tmp[0], tmp[1].split(',')\n",
        "        layer_params_dict = dict({})\n",
        "        for param in layer_params:\n",
        "          param = param.split(':')\n",
        "          param_name, param_value = param[0], param[1]\n",
        "          layer_params_dict[param_name] = param_value\n",
        "        self.text_layers_dict[layer_name + str(id)] = (id, layer_params_dict)\n",
        "        id += 1\n",
        "      #print(self.text_layers_dict)\n",
        "\n",
        "    def get_text_layers_dict(self):\n",
        "      return self.text_layers_dict\n",
        "\n",
        "    def get_nn_len(self):\n",
        "      return self.nn_len\n",
        "\n",
        "    def conv_output_shape(self, h, w, kernel_size=1, stride=1, pad=0, dilation=1):\n",
        "      '''\n",
        "      Calculates output of layer by input shape [B, C, H, W]\n",
        "      return: h - int, w - int\n",
        "      '''\n",
        "\n",
        "      h = math.floor( ((h + (2 * pad) - ( dilation * (kernel_size - 1) ) - 1 )/ stride) + 1)\n",
        "      w = math.floor( ((w + (2 * pad) - ( dilation * (kernel_size - 1) ) - 1 )/ stride) + 1)\n",
        "      return h, w\n",
        "\n",
        "    def generateNN(self, n_classes, test_batch): # -> nn.Sequential\n",
        "      '''\n",
        "      most important part of that class\n",
        "      Build Neural Network\n",
        "      Algorithm:\n",
        "      1) extract layer params\n",
        "      2) create layer\n",
        "      3) assert NN with that layer will be correct\n",
        "      4) append layer to the backbone\n",
        "      5) repeat 1-4 for all layers\n",
        "      6) append linear classifier\n",
        "\n",
        "      n_classes: amount of classification classes\n",
        "      test_batch: test data for input data shape extraction\n",
        "      return success_state: bool (True if created successfully), net: nn.Sequential\n",
        "      '''\n",
        "      success_state = False\n",
        "      backbone = nn.Sequential()\n",
        "      classifier = nn.Sequential()\n",
        "      optimizer = None\n",
        "      try:\n",
        "        data_shape = np.array(test_batch).shape # [B, C, H, W]\n",
        "        last_shape = data_shape\n",
        "        for layer_name in self.text_layers_dict.keys():\n",
        "            layer = None\n",
        "            layer_params= self.text_layers_dict[layer_name][1] # [0] - id\n",
        "            if layer_name.find('conv') >= 0:\n",
        "              # 'conv=channel_factor:2,kernel_size:5,stride:1,padding:0-',\n",
        "              kernel_size = int(layer_params['kernel_size'])\n",
        "              channel_factor = float(layer_params['channel_factor'])\n",
        "              stride = int(layer_params['stride'])\n",
        "              padding = int(layer_params['padding'])\n",
        "              dilation = 1\n",
        "\n",
        "              activation = nn.ReLU(inplace=True)\n",
        "\n",
        "              in_chan = last_shape[1]\n",
        "\n",
        "              assert(in_chan <= last_shape[2] and in_chan <= last_shape[3])\n",
        "              assert(last_shape[3] > kernel_size and last_shape[2] > kernel_size)\n",
        "              out_chan = math.floor(in_chan * channel_factor)\n",
        "              assert(out_chan > 0)\n",
        "\n",
        "              backbone.append(nn.Conv2d(in_chan, out_chan, kernel_size, stride, padding, dilation))\n",
        "              backbone.append(activation)\n",
        "\n",
        "              h, w = self.conv_output_shape(last_shape[2], last_shape[3], kernel_size, stride, padding, dilation)\n",
        "              last_shape = (last_shape[0], out_chan, h, w)\n",
        "\n",
        "            elif layer_name.find('batchnorm') >= 0:\n",
        "              eps = float(layer_params['eps'])\n",
        "              in_chan = last_shape[1]\n",
        "              backbone.append(nn.BatchNorm2d(in_chan, eps))\n",
        "\n",
        "            elif layer_name.find('avgpool') >= 0:\n",
        "              # 'avgpool=kernel_size:2,stride:2,padding:0-',\n",
        "              kernel_size = int(layer_params['kernel_size'])\n",
        "              stride = int(layer_params['stride'])\n",
        "              padding = int(layer_params['padding'])\n",
        "              dilation = 1\n",
        "              in_chan = last_shape[1]\n",
        "              out_chan = in_chan\n",
        "\n",
        "              assert(in_chan <= last_shape[2] and in_chan <= last_shape[3])\n",
        "              assert(last_shape[3] > kernel_size and last_shape[2] > kernel_size)\n",
        "\n",
        "              backbone.append(nn.AvgPool2d(kernel_size, stride, padding))\n",
        "\n",
        "              h, w = self.conv_output_shape(last_shape[2], last_shape[3], kernel_size, stride, padding, dilation)\n",
        "              last_shape = (last_shape[0], out_chan, h, w)\n",
        "\n",
        "\n",
        "            elif layer_name.find('maxpool') >= 0:\n",
        "              # 'maxpool=kernel_size:2,stride:2,padding:0-',\n",
        "              kernel_size = int(layer_params['kernel_size'])\n",
        "              stride = int(layer_params['stride'])\n",
        "              padding = int(layer_params['padding'])\n",
        "              dilation = 1\n",
        "              in_chan = last_shape[1]\n",
        "              out_chan = in_chan\n",
        "              assert(in_chan <= last_shape[2] and in_chan <= last_shape[3])\n",
        "              assert(last_shape[3] > kernel_size and last_shape[2] > kernel_size)\n",
        "\n",
        "              backbone.append(nn.MaxPool2d(kernel_size, stride, padding))\n",
        "\n",
        "              h, w = self.conv_output_shape(last_shape[2], last_shape[3], kernel_size, stride, padding, dilation)\n",
        "              last_shape = (last_shape[0], out_chan, h, w)\n",
        "\n",
        "            elif layer_name.find('dropout') >= 0:\n",
        "              p = float(layer_params['p'])\n",
        "              backbone.append(nn.Dropout2d(p))\n",
        "        linear_in_shape = last_shape[1] * last_shape[2] * last_shape[3]\n",
        "        classifier = nn.Linear(linear_in_shape, n_classes)\n",
        "        success_state = True\n",
        "        #print('NN build successfull!')\n",
        "\n",
        "      except Exception as e:\n",
        "        #print('NN build failed!')\n",
        "        #print(str(e))\n",
        "        pass\n",
        "\n",
        "      net = nn.Sequential()\n",
        "      net.append(backbone)\n",
        "      net.append(nn.Flatten(start_dim=1))\n",
        "      net.append(classifier)\n",
        "      self.text_layers_dict = dict({})\n",
        "      return success_state, net\n",
        "\n",
        "\n",
        "  def seed(self, seed=None):\n",
        "      from gymnasium.utils import seeding\n",
        "      self.np_random, seed = seeding.np_random(seed)\n",
        "      #seed = 42\n",
        "      return [seed]\n",
        "\n",
        "\n",
        "  def calc_reward(self, nn_created_correctly_flag, nn_len, last_train_metrics):\n",
        "    '''\n",
        "       calculate agent reward\n",
        "\n",
        "       nn_created_correctly_flag: bool,\n",
        "       if True - NN was built successfully,\n",
        "       we can calculate other parts of reward,\n",
        "       otherwise - agent takes NN_CREATE_NOT_SUCCESS_PENALTY only\n",
        "\n",
        "       nn_len: int,\n",
        "       that var needed for depth decreasing reward\n",
        "       # Not used (future) #\n",
        "\n",
        "       last_train_metrcis: np.array,\n",
        "       contains last training loop metrics\n",
        "       for metrics_optimization_reward\n",
        "\n",
        "       return reward: float, sum of all reward parts\n",
        "\n",
        "    '''\n",
        "\n",
        "    reward = 0\n",
        "    # TODO reward for decreasing nn depth\n",
        "    optimal_depth_reward = 0\n",
        "    # reward by metrics\n",
        "    metrics_optimization_reward = 0\n",
        "    # reward for successfull nn creation\n",
        "    creation_successfull_reward = 0\n",
        "    if nn_created_correctly_flag == True:\n",
        "      # do not reward agent if creation is not succeed\n",
        "      creation_successfull_reward += self.NN_CREATE_SUCCESS_REWARD\n",
        "\n",
        "      last_metrics = self.NN_PARAMS['metrics'][-1]\n",
        "      last_train_metrics = np.nan_to_num(x=last_train_metrics, nan=self.NAN_NUM)\n",
        "      last_train_metrics = np.minimum(last_train_metrics,\n",
        "                          np.ones(shape=(self.NN_PARAMS['amount_of_metrics'], self.NN_PARAMS['train_epochs'])) * self.NAN_NUM\n",
        "                          )\n",
        "\n",
        "      tmp_r = np.min(last_metrics,axis=1) - np.min(np.array(last_train_metrics), axis=1)\n",
        "\n",
        "\n",
        "      self.NN_PARAMS['metrics'] = np.roll(self.NN_PARAMS['metrics'], -1, axis=0)\n",
        "      self.NN_PARAMS['metrics'][-1] = last_train_metrics\n",
        "      metrics_optimization_reward = np.sum(self.METRICS_OPTIMIZATION_FACTOR * tmp_r)\n",
        "\n",
        "      optimal_depth_reward = (self.NN_PARAMS['layers_amount'] - nn_len)\n",
        "      optimal_depth_reward *= self.DEPTH_REWARD_FACTOR\n",
        "\n",
        "    else:\n",
        "      creation_successfull_reward += self.NN_CREATE_NOT_SUCCESS_PENALTY\n",
        "\n",
        "    reward += optimal_depth_reward\n",
        "    reward += metrics_optimization_reward\n",
        "    reward += creation_successfull_reward\n",
        "\n",
        "    return reward\n",
        "\n",
        "  def get_test_batch(self):\n",
        "    '''\n",
        "        return: batch: np.array, one batch\n",
        "        for input_shape in NN building algorithm\n",
        "\n",
        "    '''\n",
        "    batch = None\n",
        "    for  b, _ in self.train_dataloader:\n",
        "      batch = b\n",
        "    return batch\n",
        "\n",
        "  def create_obs(self):\n",
        "    '''\n",
        "       return obs: dict, new observation\n",
        "    '''\n",
        "\n",
        "    obs = {\n",
        "          'last_nets_metrics_memory': self.NN_PARAMS['metrics'],\n",
        "          'last_nets_architectures': self.NN_PARAMS['last_nets_architectures']\n",
        "\n",
        "          }\n",
        "    return obs\n",
        "\n",
        "  def step(self, action):\n",
        "      '''\n",
        "          Main environment function\n",
        "\n",
        "          takes action, creates NN, train NN, calc new obs and reward\n",
        "\n",
        "          action: list, shape of action is like action_space\n",
        "\n",
        "      return:\n",
        "      obs: np.array,\n",
        "      reward: float,\n",
        "      done = False, end of agent training flag, needed when your actions\n",
        "      achieved some finish state\n",
        "      info: dict, you may need to add some extra information, put it here\n",
        "\n",
        "      Algorithm\n",
        "      1) parse action\n",
        "      2) generate NN\n",
        "      3) update optimizer, prepare for training\n",
        "      4) train NN, collect metrics\n",
        "      5) calculate reward\n",
        "      6) collect statistics\n",
        "      7) create new observation\n",
        "      8) return obs, reward, done, info\n",
        "\n",
        "      '''\n",
        "      reward = 0\n",
        "      done = False\n",
        "      info = {}\n",
        "      self.nngenerator.parse_action(action, self.actions_set)\n",
        "      test_b = self.get_test_batch()\n",
        "      success_state, net = self.nngenerator.generateNN(n_classes=self.NN_PARAMS['num_classes'], test_batch=test_b)\n",
        "\n",
        "      new_metrics = None\n",
        "      if success_state == True: # NN created_correctly\n",
        "        self.NN_PARAMS['last_nets_architectures'] = np.roll(self.NN_PARAMS['last_nets_architectures'], -1, axis=0)\n",
        "        self.NN_PARAMS['last_nets_architectures'][-1] = action\n",
        "        self.Net.layers = net\n",
        "        display(self.Net)\n",
        "        self.Net = self.Net.to(self.device)\n",
        "        self.optimizer = self.optimizer_class(self.Net.parameters(), lr=self.NN_PARAMS['lr'])\n",
        "        new_metrics = self.train()\n",
        "\n",
        "\n",
        "      reward = self.calc_reward(success_state,\n",
        "                                self.nngenerator.get_nn_len(),\n",
        "                                new_metrics,\n",
        "                                )\n",
        "\n",
        "\n",
        "      current_obs = self.create_obs()\n",
        "\n",
        "      self.last_obs = current_obs\n",
        "\n",
        "      print('Reward: ', reward)\n",
        "      self.episode_reward = reward\n",
        "      self.current_it += 1\n",
        "      return current_obs, self.episode_reward, None, done, info\n",
        "\n",
        "\n",
        "  def reset(self, seed=None, options=None):\n",
        "      '''\n",
        "      Reset the env,\n",
        "      Set all changed in training proccess variables to zero\n",
        "      (or noise, dependse on your realization)\n",
        "\n",
        "      seed: list, list of random seeds (depricated)\n",
        "      options: list, additional options (future)\n",
        "      '''\n",
        "      super().reset(seed=seed)\n",
        "      self.Net = self.NN()\n",
        "\n",
        "      current_obs = {\n",
        "          'last_nets_metrics_memory': np.zeros((\n",
        "              self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "              self.NN_PARAMS['amount_of_metrics'],\n",
        "              self.NN_PARAMS['train_epochs'],\n",
        "             ) ),\n",
        "          'last_nets_architectures': np.zeros((\n",
        "             self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "             self.NN_PARAMS['layers_amount'],\n",
        "          ) )\n",
        "\n",
        "          }\n",
        "      self.NN_PARAMS['metrics'] = np.zeros((\n",
        "          self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "          self.NN_PARAMS['amount_of_metrics'],\n",
        "          self.NN_PARAMS['train_epochs'],\n",
        "      ))\n",
        "      self.NN_PARAMS['last_nets_architectures'] = np.zeros((\n",
        "             self.NN_PARAMS['last_nets_metrics_memory_len'],\n",
        "             self.NN_PARAMS['layers_amount'],\n",
        "          ))\n",
        "\n",
        "      self.last_obs = current_obs\n",
        "      self.episode_reward = 0\n",
        "      self.current_it = 1\n",
        "\n",
        "      self.statistics['episode_rewards'] = []\n",
        "      self.statistics['made_steps'] = []\n",
        "\n",
        "      return current_obs, {'none': None}\n",
        "\n",
        "\n",
        "\n",
        "  def render(self, mode=None):\n",
        "    '''\n",
        "    method for visualisation your observation\n",
        "    example: render method for labirint task contains some\n",
        "    visualization of map, agent, finish point, etc.\n",
        "    '''\n",
        "    #TODO visualization\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "  def close(self):\n",
        "      '''\n",
        "          environment destructor\n",
        "      '''\n",
        "      # TODO\n",
        "      pass\n",
        "    \"\"\"\n",
        "    for name in stage_names:\n",
        "        env_class = 'class {}(gym.Env):'.format(''.join([s.capitalize() for s in name.split('_')]))\n",
        "        with open('gym_{}/envs/{}.py'.format(env_name, name), 'w') as f:\n",
        "            f.write(head + env_class + tail)\n",
        "    pass\n",
        "\n",
        "\n",
        "def make_setup(env_name):\n",
        "    with open('setup.py', 'w') as f:\n",
        "        tmp = [\n",
        "            'from setuptools import setup\\n\\n',\n",
        "            \"setup(name='gym_{}',\\n\".format(env_name),\n",
        "            \"    version='0.0.1',\\n\",\n",
        "            \"    install_requires=['gym']  # And any other dependencies foo needs\\n\",\n",
        "            \")\\n\",\n",
        "        ]\n",
        "        f.writelines(tmp)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    env_name = 'env'# input('Please type your env\\'s name (string):')\n",
        "    env_stage_num = 1 #int(input('Type the stage number of your Env (int):'))\n",
        "\n",
        "    print(\n",
        "        'Please type yout stage names\\n(start with alphabet, lowercase and number, split by underscore(_), e.g. my_env_v1)')\n",
        "    env_stage_names = ['env']\n",
        "    #for i in range(env_stage_num):\n",
        "    #    env_stage_names.append(input(\"Stage {}s name:\".format(i)))\n",
        "\n",
        "    make_dirs(env_name)\n",
        "    make_files(env_name, env_stage_names)\n",
        "    #generate_setup = input('Generate `setup.py`?[y/n]')\n",
        "\n",
        "    generate_setup = 'y'\n",
        "    if generate_setup.lower() == 'y':\n",
        "        make_setup(env_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chWNrVWltHNg",
        "outputId": "19a76b5f-4b0e-40b0-aa21-f0fbc19db9b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/178.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable_baselines3)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.0.1+cu118)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable_baselines3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->stable_baselines3) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Installing collected packages: farama-notifications, gymnasium, stable_baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable_baselines3-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK_yA57N030I",
        "outputId": "9599b900-ff0c-4aad-ee8f-356e13be45cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy==0.2.1\n",
            "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy==0.2.1) (1.23.5)\n",
            "Requirement already satisfied: gymnasium>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from shimmy==0.2.1) (0.29.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==0.2.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==0.2.1) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==0.2.1) (0.0.4)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install shimmy==0.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAclCMrtxS8t",
        "outputId": "505e11b3-782c-4417-8136-d49de086b8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import *\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from gymnasium.envs.registration import register\n",
        "import gymnasium"
      ],
      "metadata": {
        "id": "rdKuNzOKUe5i"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zNp1XvEYsykV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc9d8c4-557f-4534-9201-0a8f47342452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment gym_env/env_v1-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "register(\n",
        "    id='gym_env/env_v1-v0',\n",
        "    entry_point='gym_env.envs:Env',\n",
        "    max_episode_steps=300,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download pytorch CIFAR10 Dataset\n",
        "train_data = dsets.CIFAR10(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_data = dsets.CIFAR10(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sxgqOicVHWC",
        "outputId": "95ddee5f-722e-4a0c-cfc0-dfd40b31d5a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLT7L4cKytU0",
        "outputId": "e19b5b77-e377-4434-a27f-385172012f61"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = np.array(train_data.data)[:15000].transpose((0,3,1,2)) # convert to [B, C, H, W]"
      ],
      "metadata": {
        "id": "RE-X_dlCVOrQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_data.targets)[:15000]"
      ],
      "metadata": {
        "id": "gdbA9KJrVOuG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple custom dataset template\n",
        "class myDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "\n",
        "      self.X = X\n",
        "      self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_ = self.X[idx]\n",
        "        y_ = self.y[idx]\n",
        "        return x_, y_"
      ],
      "metadata": {
        "id": "meMXGhX_VHYn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = myDataset(X=train_samples, y=train_labels)"
      ],
      "metadata": {
        "id": "YF1S-cDdVHbF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, valid_set = torch.utils.data.random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "id": "1DkKMJ6EVHd2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  train_set,\n",
        "  batch_size=32,\n",
        "  shuffle=True,\n",
        "  drop_last=True)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "  valid_set,\n",
        "  batch_size=32,\n",
        "  drop_last=True,\n",
        "  shuffle=True)"
      ],
      "metadata": {
        "id": "IrIY17b1VHgC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some environment params\n",
        "# optimizer should be class\n",
        "# because every NN building needs\n",
        "# pass model.params() to optimizer,\n",
        "# so we will recreate optimizer every\n",
        "# time new NN will be created successfully\n",
        "\n",
        "env_params = {\n",
        "    'opt_cls': torch.optim.RAdam,\n",
        "    'trn_ldr': train_loader,\n",
        "    'vld_ldr': valid_loader,\n",
        "    'crit': torch.nn.MSELoss(),\n",
        "}"
      ],
      "metadata": {
        "id": "TOO0FPvxT6CB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "igZtRH4Zs8R0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c02dd0d-2f11-4a38-d2e4-5f34606d1597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:521: UserWarning: \u001b[33mWARN: Using the latest versioned environment `gym_env/env_v1-v0` instead of the unversioned environment `gym_env/env_v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "env = gymnasium.make('gym_env/env_v1', **env_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kqOphei6tUF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747b72b2-c8c2-49d8-80a4-485080123793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# Proximal Policy Optimization\n",
        "# doc: https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html\n",
        "\n",
        "model = PPO(\"MultiInputPolicy\", env, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mIbWb2AAl8Ol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81fd5a70-658a-4a4c-fda2-c17d14f784d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:228: UserWarning: \u001b[33mWARN: Expects `terminated` signal to be a boolean, actual type: <class 'NoneType'>\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
            "  logger.warn(f\"{pre} is not within the observation space.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Dropout2d(p=0.1, inplace=False)\n",
              "      (1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(24, 19, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Conv2d(19, 15, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(15, 12, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=5808, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:17<00:00,  1.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -198.4\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.2, inplace=False)\n",
              "      (3): Dropout2d(p=0.1, inplace=False)\n",
              "      (4): Conv2d(2, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(16, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=123904, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:19<00:00,  1.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  184.96146354675292\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(12, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Dropout2d(p=0.2, inplace=False)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=2304, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:12<00:00,  1.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  4.882211303710937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout2d(p=0.1, inplace=False)\n",
              "      (2): Conv2d(3, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Dropout2d(p=0.1, inplace=False)\n",
              "      (5): Dropout2d(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=784, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:10<00:00,  1.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -2.974756622314453\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.2, inplace=False)\n",
              "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(24, 19, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(19, 11, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=5324, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:13<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  7.891704654693603\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      (1): Dropout2d(p=0.1, inplace=False)\n",
              "      (2): Dropout2d(p=0.1, inplace=False)\n",
              "      (3): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Conv2d(2, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:10<00:00,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -3.344358348846436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.1, inplace=False)\n",
              "      (3): Dropout2d(p=0.1, inplace=False)\n",
              "      (4): Dropout2d(p=0.2, inplace=False)\n",
              "      (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=392, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:09<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -5.165955924987793\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.2, inplace=False)\n",
              "      (3): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=1152, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:11<00:00,  1.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  10.80641279220581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(12, 9, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      (5): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): Conv2d(9, 36, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=4356, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:13<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  4.335777378082275\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.2, inplace=False)\n",
              "      (3): Conv2d(24, 96, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=55296, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:16<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -2.5153836250305175\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.1, inplace=False)\n",
              "      (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      (4): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=800, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:11<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  0.5339537620544434\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Dropout2d(p=0.1, inplace=False)\n",
              "      (1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(12, 9, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Conv2d(9, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(7, 5, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=2000, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:13<00:00,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -5.467173004150391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(24, 14, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(14, 56, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=27104, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:14<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  16.92555150985718\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(12, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      (5): Conv2d(7, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:12<00:00,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -6.656600856781006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Dropout2d(p=0.2, inplace=False)\n",
              "      (1): Dropout2d(p=0.1, inplace=False)\n",
              "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (3): Dropout2d(p=0.1, inplace=False)\n",
              "      (4): Dropout2d(p=0.2, inplace=False)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=768, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:08<00:00,  1.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -181.8128465652466\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(12, 7, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (7): Conv2d(4, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=2048, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:12<00:00,  1.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  185.00303421020507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(2, 1, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Conv2d(4, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (7): ReLU(inplace=True)\n",
              "      (8): Conv2d(16, 9, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (9): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=1764, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:13<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  4.251536464691162\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.2, inplace=False)\n",
              "      (3): Dropout2d(p=0.1, inplace=False)\n",
              "      (4): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Conv2d(12, 96, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=75264, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:13<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  3.6929832458496095\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Dropout2d(p=0.2, inplace=False)\n",
              "      (1): Dropout2d(p=0.1, inplace=False)\n",
              "      (2): Dropout2d(p=0.1, inplace=False)\n",
              "      (3): Conv2d(3, 2, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Conv2d(2, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=784, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:10<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reward:  -9.95827283859253\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n",
            "Reward:  -1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "NN(\n",
              "  (layers): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Dropout2d(p=0.1, inplace=False)\n",
              "      (1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "      (2): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=400, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 2/11 [00:02<00:11,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c1ca84c8dd29>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gym_env/envs/env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNN_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0mnew_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gym_env/envs/env.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.learn(total_timesteps=10000)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vivgM9EbDog"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}